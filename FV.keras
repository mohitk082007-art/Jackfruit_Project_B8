import pandas as pd
from pathlib import Path
import os.path
import kagglehub
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import streamlit as st
from PIL import Image
from keras.preprocessing.image import load_img, img_to_array
from keras.models import load_model
from bs4 import BeautifulSoup
import requests

def load_and_process_image(filepath):
    img_raw = tf.io.read_file(filepath)
    img = tf.image.decode_jpeg(img_raw, channels=3)
    img = tf.image.resize(img, [224, 224])  
    img = img / 255.0  
    return img

print(tf.__version__)

# Download dataset
path = kagglehub.dataset_download("kritikseth/fruit-and-vegetable-image-recognition")
print("Path to dataset files:", path)

# Using actual downloaded paths
base_path = Path(path)
train_dir = base_path / "train"
test_dir = base_path / "test"
val_dir = base_path / "validation"

train_filepaths = list(train_dir.glob(r'**/*.jpg'))
test_filepaths = list(test_dir.glob(r'**/*.jpg'))  # Fixed
val_filepaths = list(val_dir.glob(r'**/*.jpg'))    # Fixed

def image_processing(filepath):
    labels = [p.parent.name for p in filepath]  # parent folder is the label
    filepath = pd.Series(filepath, name='Filepath').astype(str).to_frame()
    labels = pd.Series(labels, name='Label')
    df = pd.concat([filepath, labels], axis=1)
    df = df.sample(frac=1).reset_index(drop=True)
    return df

train_df = image_processing(train_filepaths)
test_df = image_processing(test_filepaths)
val_df = image_processing(val_filepaths)

print('--Training set--')
print(f"Number of pictures: {train_df.shape[0]}")
print(f"Number of different labels: {len(train_df.Label.unique())}")
print(f"Labels: {train_df.Label.unique()}")
print(f"Number of training files: {len(train_filepaths)}")

train_df.head(5)
print(val_df.head())
print(val_df.columns)
print(len(val_df))

# Create a Dataframe with one Label of each category
df_unique = train_df.drop_duplicates(subset=["Label"]).reset_index(drop=True)

# Number of unique labels
num_labels = len(df_unique)

# Calculate rows and cols for subplot (e.g., 6 x 6 grid or adjust dynamically)
rows, cols = 6, 6

fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 12),
                         subplot_kw={'xticks':[], 'yticks':[]})

for i, ax in enumerate(axes.flat):
    if i < num_labels:
        img_path = df_unique.Filepath[i]
        img = plt.imread(img_path)
        ax.imshow(img)
        ax.set_title(df_unique.Label[i], fontsize=12)
    else:
        ax.axis('off')  # Hiding unused subplots

plt.tight_layout(pad=0.5)
plt.show()

train_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,
    rotation_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input
)

test_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input
)

train_image = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=0
)

val_images = val_generator.flow_from_dataframe(
    dataframe=val_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=0
)

test_images = test_generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

pretrained_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)
pretrained_model.trainable = False

inputs = pretrained_model.input

x = tf.keras.layers.Dense(128, activation="relu")(pretrained_model.output)

x = tf.keras.layers.Dense(128, activation="relu")(x)

outputs = tf.keras.layers.Dense(36, activation='softmax')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=["accuracy"]
)

history = model.fit(
    train_image,
    validation_data=val_images,
    batch_size=32,
    epochs=5,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=2,
            restore_best_weights=True
        )
    ]
)

pred = model.predict(test_images)
pred = np.argmax(pred, axis=1)
labels = (train_image.class_indices)
labels = dict((v, k) for k, v in labels.items())
pred1 = [labels[k] for k in pred]
print(pred1)

def output(location):
    img = load_img(location, target_size=(224, 224))
    img = img_to_array(img)
    img = img / 255
    img = np.expand_dims(img, [0])
    answer = model.predict(img)
    y_class = answer.argmax(axis=-1)
    y = " ".join(str(x) for x in y_class)
    y = int(y)
    res = labels[y]
    return res

# img = output('../input/fruit-and-vegetable-image-recognition/test/cabbage/Image_1.jpg')
# print(img)

model.save('FV.keras')

# labels = {0:'Apple',1: 'Banana', 2: 'Beetroot', 3: 'Bellpepper', 4: 'Cabbage', 5: 'Capsicum', 6: 'Carrot', 7: 'Cauliflower', 8: 'Chilli pepper', 9: 'Corn', 10: 'Cucumber', 11: 'Eggplant', 12: 'Garlic', 13: 'Ginger', 14: 'Grapes', 15: 'Jalapeno', 16: 'Kiwi', 17: 'Lemon', 18: 'Lettuce', 19: 'Mango', 20: 'Onion', 21: 'Orange', 22: 'Paprika', 23: 'Pear', 24: 'Peas', 25: 'Pineapple', 26: 'Pomegranate', 27: 'Potato', 28: 'Raddish', 29: 'Soya beans', 30: 'Spinach', 31: 'Sweetcorn', 32: 'Sweetpotato', 33: 'Tomato', 34: 'Turnip', 35: 'Watermelon'}

fruits = ['Watermelon','Chili pepper', 'Bellpepper','Banana', 'Grapes', 'Jalapeno', 'Kiwi', 'Lemon', 'Mango','Orange','Paprika', 'Pear', 'Peas', 'Pineapple', 'Pomegranate','Sweetcorn', 'Apple',]
vegetables = ['Beetroot', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Sweetpotato', 'Cucumber', 'Eggplant', 'Garlic', 'Ginger', 'Lettuce', 'Onion',  'Potato', 'Raddish', 'Soya beans', 'Spinach', 'Corn','Tomato', 'Turnip']  # Removed 'Lemon' to avoid duplication

def fetch_calories(prediction):
    url = 'https://www.google.com/search?q=calories+in+' + prediction
    req = requests.get(url).text
    scrap = BeautifulSoup(req, 'html.parser')
    calories = scrap.find("div", class_="BNeawe iBp4i AP7Wnd").text
    return calories
    

def processed_img(img_path):
    img = load_img(img_path, target_size=(224, 224))
    img = img_to_array(img)
    img = img / 255
    img = np.expand_dims(img, [0])
    answer = model.predict(img)
    y_class = answer.argmax(axis=-1)
    y = int(y_class[0])  # Since it's a single prediction
    res = labels[y]
    return res.capitalize()

def run():
    st.title("Fruits-Vegetable Classification")
    img_file = st.file_uploader("Choose an image", type=["jpg", "png"])
    if img_file is not None:
        img = Image.open(img_file).resize((250, 250))
        st.image(img, use_column_width=False)
        upload_dir = './upload/upload_images/'
        os.makedirs(upload_dir, exist_ok=True)
        save_image_path = os.path.join(upload_dir, img_file.name)
        with open(save_image_path, "wb") as f:
            f.write(img_file.getbuffer())

        result = processed_img(save_image_path)
        if result in vegetables:
            st.info('Category: Vegetables')
        elif result in fruits:
            st.info('Category: Fruits')
        else:
            st.info('Category: Unknown')
        st.success("Predicted: " + result)
        cal = fetch_calories(result)
        st.warning(cal + ' (100 grams)')

run()
